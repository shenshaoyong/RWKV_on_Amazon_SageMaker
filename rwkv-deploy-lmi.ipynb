{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d443515c-8e27-4ac8-937d-afed9158fda5",
   "metadata": {},
   "source": [
    "# Deploy RWKV Hugging Face models to Amazon SageMaker by using LMI, DeepSpeed \n",
    "\n",
    "reference:\n",
    "\n",
    "https://huggingface.co/RWKV\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/frameworks/djl/using_djl.html\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-dlc.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c77563-71e1-4319-8fc8-c11867cc6a72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e561c-2076-4408-8fb4-d90cf512dade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#upgrade sdk library\n",
    "!pip install -qU sagemaker\n",
    "!pip install -qU boto3\n",
    "!pip install -qU botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ed1be-985e-445c-9eee-e8fa1aecd71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sagemaker environment setting\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import shutil\n",
    "import sagemaker.huggingface\n",
    "from sagemaker.djl_inference.model import DJLModel,DeepSpeedModel,HuggingFaceAccelerateModel,DJLPredictor\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sagemaker_session is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sagemaker_session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")\n",
    "print(f\"sagemaker session region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f0932-55e5-4b1c-8ece-33b62b6d6bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_dir = 'source_dir'\n",
    "if not os.path.exists(source_dir):\n",
    "    os.mkdir(source_dir)\n",
    "#entry_point = 'entry_point.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b0513-0fdc-4339-b742-051e38529020",
   "metadata": {},
   "source": [
    "### NOTE: From v4.29.0, RWKV was supported by Transformers, the built-in Transformers(4.26.0) needs to be upgraded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e97a5-5eb4-48f4-ada3-5e04cbea6d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile $source_dir/requirements.txt\n",
    "transformers==4.30.2\n",
    "boto3\n",
    "sagemaker\n",
    "sentencepiece\n",
    "nvgpu==0.9.0\n",
    "pynvml==11.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5023bede-838e-40df-922c-b917268d2660",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download model files from Hugging Face Hub, then upload them to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a49197-8750-4503-9fa6-e13e27cceb34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -L https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz | tar -xz\n",
    "#!mv s5cmd ./$source_dir/s5cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcefd54-e2fb-4831-93fb-fb714ed7cefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"RWKV/rwkv-raven-3b\"#\"RWKV/rwkv-raven-14b\"#\"RWKV/rwkv-4-169m-pile\"#\"RWKV/rwkv-raven-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06d1fb-2c79-4ed7-bf08-7e56f64d348d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47edb461-2e52-452a-8ff5-9301afdf60cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./model\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "# Only download pytorch checkpoint files\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.txt\", \"*.model\"]\n",
    "# - Leverage the snapshot library to download the model since the model is stored in repository using LFS\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_id,\n",
    "    cache_dir=local_model_path,\n",
    "    allow_patterns=allow_patterns,\n",
    ")\n",
    "\n",
    "# define a variable to contain the s3url of the location that has the model\n",
    "#stabilityai--stable-diffusion-2-1\n",
    "pretrained_model_location = f\"s3://internal-modelzoo-us-east-1/RWKV/{model_id.split('/')[1]}/\"\n",
    "\n",
    "#model_artifact = sess.upload_data(path=model_download_path, key_prefix=s3_model_prefix)\n",
    "!chmod +x ./s5cmd\n",
    "!./s5cmd sync {model_download_path}/ {pretrained_model_location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849cd48-e1cf-4db8-8da8-c49e35801392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model_download_path)\n",
    "print(pretrained_model_location)\n",
    "#!./s5cmd sync {model_download_path}/  {pretrained_model_location}\n",
    "!rm -fr {local_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6386a49-c18e-427b-908a-6c9442b370dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LMI + Create a model using the DeepSpeed backend, then do inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca797b94-a274-435c-b6cb-efcfaaedd053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LMI + Create a model using the DeepSpeed backend\n",
    "model_id = \"s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/\"\n",
    "print(f\"model_id:{model_id}\")\n",
    "\n",
    "deepspeed_model = DeepSpeedModel(\n",
    "    model_id, # This can also be a HuggingFace Hub model id\n",
    "    role,\n",
    "    dtype=\"fp16\",\n",
    "    task=\"text-generation\",\n",
    "    tensor_parallel_degree=1, # number of gpus to partition the model across using tensor parallelism\n",
    "    #entry_point = entry_point,\n",
    "    source_dir = source_dir,\n",
    ")\n",
    "\n",
    "# Deploy the model to an Amazon SageMaker Endpoint and get a Predictor\n",
    "print(f\"Deploying..., please wait for 3-10 minutes!\")\n",
    "deepspeed_predictor = deepspeed_model.deploy(\n",
    "    \"ml.g5.2xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    model_data_download_timeout=10*60,\n",
    "    container_startup_health_check_timeout=15*60\n",
    ")\n",
    "endpoint_name = deepspeed_predictor.endpoint_name\n",
    "print(\"\")\n",
    "print(f\"endpoint_name:{endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0146ed-0100-4ecd-8cb3-477d950dbba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "print(deepspeed_predictor.predict(\n",
    "    { \n",
    "        \"inputs\" : \"American election is\", \n",
    "        \"parameters\": { \"max_length\": 50 },\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6ae81-8ed1-424f-882d-b6ad15daf227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # LMI + Create a model using the HuggingFace Accelerate backend\n",
    "# model_id = \"s3://internal-modelzoo-us-east-1/RWKV/rwkv-raven-3b/\"\n",
    "# print(f\"model_id:{model_id}\")\n",
    "\n",
    "# hf_accelerate_model = HuggingFaceAccelerateModel(\n",
    "#     model_id, # This can also be a HuggingFace Hub model id\n",
    "#     role,\n",
    "#     dtype=\"fp16\",\n",
    "#     task=\"text-generation\",\n",
    "#     number_of_partitions=1, # number of gpus to partition the model across\n",
    "#     #entry_point = entry_point,\n",
    "#     source_dir = source_dir\n",
    "# )\n",
    "# # Deploy the model to an Amazon SageMaker Endpoint and get a Predictor\n",
    "# print(f\"Deploying..., please wait for 3-10 minutes!\")\n",
    "\n",
    "# hf_accelerate_predictor = hf_accelerate_model.deploy(\"ml.g5.2xlarge\",\n",
    "#                                                      initial_instance_count=1,\n",
    "#                                                      model_data_download_timeout=10*60,\n",
    "#                                                      container_startup_health_check_timeout=15*60)\n",
    "# #predict\n",
    "# print(hf_accelerate_predictor.predict(\n",
    "#     { \n",
    "#         \"inputs\" : \"Large model inference is\", \n",
    "#         \"parameters\": { \"max_length\": 50 },\n",
    "#     }\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ffdb84-8f17-43ca-b5fe-348d01a27de8",
   "metadata": {},
   "source": [
    "## ONLY for re-invoke already-created endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab252a6b-e7a4-4253-8281-85deff803b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#only for re-invoke already-created endpoint\n",
    "endpoint_name=\"djl-inference-2023-06-18-14-37-50-264\"\n",
    "endpoint_name=\"djl-inference-2023-08-10-06-10-14-302\"\n",
    "from sagemaker.djl_inference.model import DJLPredictor\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "predictor = DJLPredictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")\n",
    "#predict\n",
    "print(predictor.predict(\n",
    "    { \n",
    "        \"inputs\" : \"Today is sunny,\", \n",
    "        \"parameters\": { \"max_length\": 50 },\n",
    "    }\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0176edd-0a56-4756-ba05-698db2464447",
   "metadata": {},
   "source": [
    "## clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85351ea4-e0e0-4194-b07c-605f243abd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint_name = \"\"\n",
    "#model_name = \"\"\n",
    "#sagemaker_session.delete_endpoint(endpoint_name)\n",
    "#sagemaker_session.delete_endpoint_config(endpoint_name)\n",
    "#sagemaker_session.delete_model(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc254fc-0506-4d29-9990-4a2f33a942b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
